#########################################################################################################
# Configuración API keys 
#########################################################################################################

OPENAI_API_KEY=tu-api-key-de-openai

#########################################################################################################
# Configuración del LLM  
#########################################################################################################

# Proveedor de LLM AI Agent base (De momento solo OPENAI)
LLM_PROVIDER=OPENAI
# Modelo de LLM a utilizar por el chatbot, por ejemplo:
# LLM_MODEL=gpt-4o-mini
LLM_MODEL=gpt-4o-mini-2024-07-18
# Temperatura por defecde LLM a utilizar por el chatbot
# Rango 0.0 - 1.0 (0 determinista, 1 es más creativo)
LLM_TEMPERATURE=0


# Modelo de embeddings a utilizar por el recuperador (De momento solo OPENAI)
EMBEDDING_PROVIDER=OPENAI
# Número de documentos máximos recuperados por la búsqueda semántica
RETRIEVER_LIMIT=25


# Proveedor de LLM para generación de scripts SQL (De momento solo OPENAI)
SQL_LLM_PROVIDER=OPENAI
# Modelo de LLM para generación de scripts SQL
SQL_LLM_MODEL=o4-mini-2025-04-16
# Temperatura para generación de scripts SQL
SQL_LLM_TEMPERATURE=1

#########################################################################################################
# Configuración de la carga de colleciones en Qdrant 
#########################################################################################################
# Configuración conexión a Qdrant (si no se ha cambiado nada en docker-compose.yml dejar como está)
QDRANT_URL=http://localhost:6336
# Nombre de la colección en Qdrant
BASE_COLLECTION_NAME=knowledge-mimic-iv
# Proveedor de embeddings que se usará para la carga en Qdrant
LOAD_EMBEDDING_MODEL_OPENAI=text-embedding-3-small
# Vector size para embeddings de OpenAI
OPENAI_EMBEDDING_VECTOR_SIZE=1536

##########################################################################################################
# Configuración Monitorización Experimentos 
##########################################################################################################
# Monitoriza las invocaciones de la herramienta `search_and_generate_sql
# Salidas en formato `.json` en directorio `output/`
DATA_EXPERIMENT=YES

##########################################################################################################
# Authentication  
##########################################################################################################
# El repositorio público tiene una clase auth.py fake para simular el login de usuario.
# Si quieres simular el comportamiento indica YES, e introduce user: demo | pass: demo en el login.
# Si te ha gustado mi proyecto y quieres subir algo similar a producción recuerda desarrollar el módulo
# auth según las necesidades de tu proveedor de autenticación.
# No se publica la verdadera clase auth.py para evitar exponer vulnerabilidades no detectadas.
AUTH_REQUIRED=NO #YES o NO

##########################################################################################################
# Configuración de la conexión a la base de datos postgres 
# Únicamente es necesario para results/result_generator.py
#
# No se utiliza en ninguna otra parte del proyecto.
# 
##########################################################################################################
DB_USER=tusdatos
DB_PASSWORD=tusdatos
DB_HOST=tusdatos
DB_PORT=tusdatos
DB_NAME=tusdatos
